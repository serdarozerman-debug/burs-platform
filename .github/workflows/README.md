# ğŸ¤– OTOMATIK SCRAPING SÄ°STEMÄ°

**Durum:** âœ… AKTIF  
**Platform:** GitHub Actions  
**Maliyet:** Ãœcretsiz (public repo)

---

## ğŸ“‹ Ã‡ALIÅAN Ä°ÅLER

### 1. ğŸ” **Yeni Kurum KeÅŸfi** (discover-organizations.yml)

**Ne Yapar:**
- Yeni burs veren kurumlarÄ± araÅŸtÄ±rÄ±r
- `organizations.json` dosyasÄ±nÄ± gÃ¼nceller
- Otomatik commit ve push yapar

**Ã‡alÄ±ÅŸma Takvimi:**
```
ğŸ“… Her 15 gÃ¼nde bir
â° AyÄ±n 1. ve 15. gÃ¼nÃ¼, saat 03:00 UTC (06:00 TR)
â±ï¸ Tahmini sÃ¼re: 30-60 dakika
```

**Manuel Ã‡alÄ±ÅŸtÄ±rma:**
```
GitHub â†’ Actions â†’ "Discover New Organizations" â†’ Run workflow
```

---

### 2. ğŸ“ **Burs Scraping** (scrape-scholarships.yml)

**Ne Yapar:**
- Mevcut kurumlardan burs verilerini Ã§eker
- Supabase'e otomatik yÃ¼kler
- Duplicate kontrolÃ¼ yapar
- Scraping raporu oluÅŸturur

**Ã‡alÄ±ÅŸma Takvimi:**
```
ğŸ“… Her 5 gÃ¼nde bir (ayda 6 kez)
â° AyÄ±n 1, 6, 11, 16, 21, 26. gÃ¼nleri, saat 02:00 UTC (05:00 TR)
â±ï¸ Tahmini sÃ¼re: 60-90 dakika
```

**Scraper SeÃ§enekleri:**
- `non-universities`: Sadece vakÄ±flar ve kurumlar (Ã¶nerilen)
- `all`: TÃ¼m organizasyonlar (Ã¼niversiteler dahil)
- `advanced`: AI-powered scraper (OpenAI gerekli)

**Manuel Ã‡alÄ±ÅŸtÄ±rma:**
```
GitHub â†’ Actions â†’ "Scrape Scholarships" â†’ Run workflow
Parameters:
  - Scraper type: non-universities/all/advanced
  - Limit: 50 (varsayÄ±lan)
```

---

## ğŸ”§ KURULUM

### 1. GitHub Secrets Ekle

**Repository â†’ Settings â†’ Secrets and variables â†’ Actions**

Åu secrets'larÄ± ekleyin:

```
SUPABASE_URL=https://hzebnzsjuqirmkewwaol.supabase.co
SUPABASE_ANON_KEY=eyJhbGci...
OPENAI_API_KEY=sk-... (opsiyonel, advanced scraper iÃ§in)
```

### 2. Actions'Ä± AktifleÅŸtir

**Repository â†’ Actions â†’ Enable Actions**

```
âœ… I understand my workflows, go ahead and enable them
```

### 3. Ä°lk Ã‡alÄ±ÅŸtÄ±rmayÄ± Test Et

**Actions â†’ "Scrape Scholarships" â†’ Run workflow**

```
Scraper type: non-universities
Limit: 10
```

---

## ğŸ“Š TAKVÄ°M Ã–ZETÄ°

### AylÄ±k Schedule (Ã–rnek: KasÄ±m 2024)

```
KasÄ±m 1:  ğŸ” Organization Discovery + ğŸ“ Scholarship Scraping
KasÄ±m 6:                             ğŸ“ Scholarship Scraping
KasÄ±m 11:                            ğŸ“ Scholarship Scraping
KasÄ±m 15: ğŸ” Organization Discovery
KasÄ±m 16:                            ğŸ“ Scholarship Scraping
KasÄ±m 21:                            ğŸ“ Scholarship Scraping
KasÄ±m 26:                            ğŸ“ Scholarship Scraping
```

**Toplam:**
- Organization Discovery: 2 kez/ay
- Scholarship Scraping: 6 kez/ay

---

## ğŸ“ˆ BEKLENEN SONUÃ‡LAR

### Organization Discovery:
```
Her Ã§alÄ±ÅŸtÄ±rmada:
  - 5-20 yeni kurum bulunabilir
  - organizations.json gÃ¼ncellenir
  - Otomatik commit yapÄ±lÄ±r
```

### Scholarship Scraping:
```
Her Ã§alÄ±ÅŸtÄ±rmada:
  - 50-200 burs Ã§ekilir
  - Yeni burslar eklenir
  - Eski burslar gÃ¼ncellenir
  - Deadline geÃ§enler is_active=false yapÄ±lÄ±r
  - Duplicate'ler temizlenir
```

---

## ğŸ” Ä°ZLEME

### Logs GÃ¶rÃ¼ntÃ¼leme

**GitHub â†’ Actions â†’ Ä°lgili workflow â†’ Run details**

```
âœ… Her step'in loglarÄ±
âœ… Hata mesajlarÄ±
âœ… Scraping raporu (artifact olarak)
```

### Email Bildirimleri

**GitHub Settings â†’ Notifications**

```
âœ… Actions: Workflow run failures
âœ… Email'e bildirim al
```

---

## âš™ï¸ YAPITLANDIRMA

### Cron Syntax DeÄŸiÅŸtirme

**discover-organizations.yml:**
```yaml
schedule:
  # Her hafta Pazartesi sabah 9
  - cron: '0 9 * * 1'
  
  # Her gÃ¼n gece yarÄ±sÄ±
  - cron: '0 0 * * *'
  
  # Her ayÄ±n ilk gÃ¼nÃ¼
  - cron: '0 0 1 * *'
```

**scrape-scholarships.yml:**
```yaml
schedule:
  # Her gÃ¼n saat 2'de
  - cron: '0 2 * * *'
  
  # Haftada 2 kez (Pazartesi ve PerÅŸembe)
  - cron: '0 2 * * 1,4'
```

**Cron Helper:** https://crontab.guru/

---

## ğŸ› SORUN Ã‡Ã–ZÃœM

### Issue: "Secrets not found"
**Ã‡Ã¶zÃ¼m:** GitHub Secrets'larÄ± kontrol et

### Issue: "Timeout"
**Ã‡Ã¶zÃ¼m:** `timeout-minutes` artÄ±r (120 â†’ 180)

### Issue: "Permission denied"
**Ã‡Ã¶zÃ¼m:** Workflow permissions'Ä± kontrol et

### Issue: "Python module not found"
**Ã‡Ã¶zÃ¼m:** requirements.txt'i kontrol et

---

## ğŸ“Š PERFORMANS

### Resource Usage (GitHub Actions):
```
Free tier limits:
  - 2,000 dakika/ay (public repo iÃ§in SINIRSIZ!)
  - Paralel jobs: 20
  - Storage: 500 MB artifacts
```

### Estimated Usage:
```
Organization Discovery: ~60 dk x 2 = 120 dk/ay
Scholarship Scraping:   ~90 dk x 6 = 540 dk/ay
---------------------------------------------
TOPLAM:                          ~660 dk/ay

âœ… Public repo ise SINIRSIZ!
âš ï¸ Private repo ise free tier aÅŸÄ±lÄ±r
```

---

## ğŸš€ PRODUCTION BEST PRACTICES

### 1. Error Handling
```python
# Scraper'lara try-catch ekle
# Supabase connection retry
# Rate limiting
```

### 2. Monitoring
```
- Sentry integration
- Email alerts on failure
- Slack notifications
```

### 3. Data Quality
```
- Duplicate detection
- Data validation
- Orphaned data cleanup
```

### 4. Scalability
```
- Parallel scraping
- Database indexing
- Caching strategy
```

---

## ğŸ“ KULLANIM

### Manuel Tetikleme

**Actions â†’ Workflow seÃ§ â†’ Run workflow**

Parametreler:
- Organization discovery: Parametre yok
- Scholarship scraping: 
  - `limit`: 10-200
  - `scraper_type`: non-universities/all/advanced

### Workflow Disable

```yaml
# GeÃ§ici olarak devre dÄ±ÅŸÄ± bÄ±rakmak iÃ§in:
on:
  # schedule:
  #   - cron: '0 3 1,15 * *'
  workflow_dispatch:  # Sadece manuel
```

### Logs Ä°ndirme

```
Actions â†’ Run â†’ Artifacts â†’ scraping-report-XXX.txt
```

---

## ğŸ¯ BAÅARILAR

âœ… Tamamen otomatik sistem  
âœ… DÃ¼zenli veri gÃ¼ncellemesi  
âœ… Yeni kurum keÅŸfi  
âœ… Manuel override mÃ¼mkÃ¼n  
âœ… Ãœcretsiz (public repo)  
âœ… Scalable  
âœ… MonitÃ¶rlenebilir  

---

**Kurulum tamamlandÄ±ÄŸÄ±nda GitHub Secrets'larÄ± eklemeyi unutmayÄ±n!**

ğŸš€ **HAPPY AUTOMATING!**

